---
layout: default
title: Learning from limited labeled data
---

# Learning from limited labeled data
Despite several recent advancements is unsupervised-learning, the performance of modern day deep learning methods still relies heavily on the size of labeled datasets. However, large-scale dataset annotation is both monotonous and painstaking. One of the focus of our group is to enable Deep Learning for various structured prediction tasks related to Speech and Natural Language processing in low resource and data-constrained settings. Our research explores better ways of harnessing human supervision beyond simply collecting gold labels [[ICLR 2020](https://openreview.net/forum?id=SkeuexBtDr), [AAAI 2020](https://arxiv.org/pdf/1911.09860.pdf)], targeted and efficient data collection [[ICASSP 2021](https://arxiv.org/abs/2103.03142)], and adaptation of ML models trained in data-abundant domains to data-constrained domains [[ACL 2021](https://arxiv.org/pdf/2106.03958.pdf), [NAACL 2021](https://arxiv.org/abs/2103.03142),  [Interspeech 2020](https://arxiv.org/pdf/2006.13519.pdf)]   

# Publications:
 * Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study \
   In ACL 2021, with Yash Khemchandani, Sarvesh Mehtani, Vaidehi Patil, Abhijeet Awasthi, Partha Talukdar, and Sunita Sarawagi \
   \[[Paper](https://arxiv.org/pdf/2106.03958.pdf)\] \[[Code](https://github.com/yashkhem1/RelateLM)\] 
 * Error-driven Fixed-Budget ASR Personalization for Accented Speakers \
   In ICASSP 2021, with Abhijeet Awasthi, Aman Kansal, Sunita Sarawagi, and Preethi Jyothi\
   \[[Paper](https://arxiv.org/abs/2103.03142)\] \[[Code](https://github.com/awasthiabhijeet/Error-Driven-ASR-Personalization)\] \[[Talk ðŸ“¢](https://youtu.be/oh3FHFz_5X0)\]
 * Training Data Augmentation for Code-Mixed Translation \
   In NAACL 2021, with Abhirut Gupta, Aditya Vavre, Sunita Sarawagi \
   \[[Paper](https://arxiv.org/abs/2103.03142)\] \[[Data](https://github.com/shruikan20/Spoken-Tutorial-Dataset)\]
 * Black-box Adaptation of ASR for Accented Speech \
   In Interspeech 2020, Kartik Khandelwal, Preethi Jyothi, Abhijeet Awasthi, Sunita Sarawagi \
   \[[Paper](https://arxiv.org/pdf/2006.13519.pdf)\] \[[Code](https://github.com/Kartik14/FineMerge)\]
 * Learning from Rules Generalizing Labeled Exemplars \
   In ICLR 2020 (**Spotlight**), with Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal, and Sunita Sarawagi \
   \[[Paper](https://openreview.net/forum?id=SkeuexBtDr)\] \[[Code and data](https://github.com/awasthiabhijeet/Learning-From-Rules)\] \[[Talk ðŸ“¢](https://youtu.be/TQfq4YdqG3k)\]
 * Data Programming using Continuous and Quality-Guided Labeling Functions \
   In AAAI 2020, with Oishik Chatterjee, Ganesh Ramakrishnan, Sunita Sarawagi \
   \[[Paper](https://arxiv.org/pdf/1911.09860.pdf)\] \[[Code and data](https://github.com/oishik75/CAGE)\]
 * Labeled Memory Networks for Online Model Adaptation \
   In AAAI 2018, with Shiv Shankar and Sunita Sarawagi \
   \[[Paper](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17141/16672)\]

# Collaborators
 * [Preethi Jyothi](https://www.cse.iitb.ac.in/~pjyothi/)
 * [Partha Pratim Talukdar](http://talukdar.net/)
 * [Abhirut Gupta](https://scholar.google.com/citations?user=Vis091UAAAAJ&hl=en)
