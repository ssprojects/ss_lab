---
layout: default
title: Learning from limited labeled data
---

# Learning from limited labeled data
Deep learning models are data hungry and annotating large datasets is a pain-staking process. One of the primary focus of our group is to develop methods to enable Deep Learning for Speech and Natural Language processing in low resource and limited labeled data settings. 

# Publications:
 * Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study \
   In ACL 2021, with Yash Khemchandani, Sarvesh Mehtani, Vaidehi Patil, Abhijeet Awasthi, Partha Talukdar, and Sunita Sarawagi \
   \[[Paper](https://arxiv.org/pdf/2106.03958.pdf)\] \[[Code](https://github.com/yashkhem1/RelateLM)\] 
 * Error-driven Fixed-Budget ASR Personalization for Accented Speakers \
   In ICASSP 2021, with Abhijeet Awasthi, Aman Kansal, Sunita Sarawagi, and Preethi Jyothi\
   \[[Paper](https://arxiv.org/abs/2103.03142)\] \[[Code](https://github.com/awasthiabhijeet/Error-Driven-ASR-Personalization)\] \[[Talk](https://youtu.be/oh3FHFz_5X0)\]
 * Learning from Rules Generalizing Labeled Exemplars \
   In ICLR 2020 (*Spotlight*), with Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal, and Sunita Sarawagi \
   \[[Paper](https://arxiv.org/abs/2004.06025)\] \[[Code](https://github.com/awasthiabhijeet/Learning-From-Rules)\] \[[Talk](https://youtu.be/TQfq4YdqG3k)\]

